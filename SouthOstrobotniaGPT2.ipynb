{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kallepalomaki/South-Ostrobotnia-GPT2/blob/main/SouthOstrobotniaGPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "**bold text**# GPT-2 Fine-Tuning experiment to Adapt Finnish GPT2 to South Ostrobotnia Accent\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKGBoVwuhM4H"
      },
      "source": [
        "This is an non-serious experiment to fine tune GPT2 in Finnish language to generate South Ostrobotnia Accent.\n",
        "\n",
        "The script is based on the following GPT-2 Fine-Tuning tutorial:\n",
        "https://colab.research.google.com/drive/13dZVYEOMhXhkXWfvSMVM1TTtUDrT6Aeh#scrollTo=0NmMdkZO8R6q\n",
        "\n",
        "Author of the script mentions other tutorials as his sources:\n",
        " \"I've liberally taken bits from [Chris McCormick's BERT fine-tuning tutorial](https://mccormickml.com/2019/07/22/BERT-fine-tuning/), [Ian Porter's GPT2 tutorial](https://snappishproductions.com/blog/2020/03/01/chapter-9.5-text-generation-with-gpt-2-and-only-pytorch.html.html) and the [Hugging Face Language model fine-tuning script](https://huggingface.co/transformers/v2.0.0/examples.html#language-model-fine-tuning) so full credit to them. Chris' code has pretty much provided the basis for this script - you should definitely check out his [blog](https://mccormickml.com/tutorials/).\"\n",
        "\n",
        "At present I've just borrowed most of original parameters without much re-tuning.\n",
        "\n",
        "GPT2 model I'm using is this: \n",
        "https://huggingface.co/Finnish-NLP/gpt2-finnish?text=Teksti%C3%A4+tuottava+teko%C3%A4ly+on\n",
        "\n",
        "version Finnish-NLP/gpt2-finnish by Aapo Tanskanen and Rasmus Toivanen\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf3Qw77SZGbS"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0188c44a-4779-45b9-fdd0-3b51429cb075"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCCeyhuDHdOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e97992d8-4b47-491e-a03c-f3d1652b8b96"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can skip training setting this False\n",
        "flag_train_model=True \n",
        "flag_run_orig_model=True"
      ],
      "metadata": {
        "id": "jwMsYk-PREND"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "satxtOn9CzgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f89d4b-2061-43ad-e8b9-26c0484d815d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Nov 19 17:49:35 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    29W /  70W |   2624MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfdCML6Parvv"
      },
      "source": [
        "# Create Training Set\n",
        "\n",
        "The data used for fine tuning the GPT2 model are blog texts that are crowled from two blog sites. http://pohopekka.blogspot.com/, https://www.blogit.fi/tag/pakina\n",
        "\n",
        "Crawling scripts are proviced separately.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EYFrNxr-TYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68cb1685-595f-40a3-d305-bc5993fc1864"
      },
      "source": [
        "# mount my Google Drive directory and access the training data located there\n",
        "gdrive_dir = '/content/gdrive/'\n",
        "data_dir = os.path.join(gdrive_dir, \"'My Drive'\",\"'Colab Notebooks'\")\n",
        "# crawled texts\n",
        "filename = 'ep.txt'\n",
        "drive.mount(gdrive_dir, force_remount=True)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_DWAMe1FopX"
      },
      "source": [
        "# copy the data to the current Colab working directory\n",
        "!cp $data_dir/$filename ."
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls $data_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oT7Hvc-h2na",
        "outputId": "2eec9bfa-e8c7-45c1-9841-b7598136d677"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Copy of GPT-2 Fine-Tuning w  Hugging Face & PyTorch.ipynb'\n",
            " ep.txt\n",
            "'language model tests.ipynb'\n",
            " model_back_up\n",
            " model_save\n",
            "'Nonlinear Sequence SimpleRNN.ipynb'\n",
            " pohopekka_dialog.txt\n",
            " seitseman_veljesta_dialog.txt\n",
            " SouthOstrobotniaGPT2.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya3zsH0r-3JK"
      },
      "source": [
        "# load into a data frame\n",
        "\n",
        "all_text=[]\n",
        "it=1\n",
        "line_text=\"\"\n",
        "with open(filename) as f:\n",
        "  for line in f:\n",
        "    line=line.strip()\n",
        "    if it % 8 == 0:\n",
        "      all_text.append(line_text)\n",
        "      line_text=\"\"\n",
        "    if len(line)>5:\n",
        "      line_text+=line + \" \"\n",
        "      line_text=line_text.replace(\" .\", \".\")\n",
        "      it+=1\n",
        "    \n",
        "all_text=pd.Series(all_text)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ1oK0kXaV5p"
      },
      "source": [
        "Following the original script we'll find out the document length distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "c319a1c3-fcec-4391-ac48-d31982c5081d"
      },
      "source": [
        "doc_lengths = []\n",
        "\n",
        "for text_item in all_text:\n",
        "\n",
        "    # get rough token count distribution\n",
        "    tokens = nltk.word_tokenize(text_item)\n",
        "\n",
        "    doc_lengths.append(len(tokens))\n",
        "\n",
        "doc_lengths = np.array(doc_lengths)\n",
        "\n",
        "sns.distplot(doc_lengths)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff5a023ea50>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD4CAYAAAD7CAEUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxd5X3n8c9PV7raF1uSV9mWvBKZHcVAIEshIaYkcSYhDZCENHVKZwppmrQzA+00TTNJWzJtaDshaUigITQJELJUTZy4EyALAQwCDHjBWJZ3y9osa7O1/+aPe+QKod333Ksrfd+vl1669znPOfqda9k/P8t5HnN3REREJist2QGIiEhqUeIQEZEpUeIQEZEpUeIQEZEpUeIQEZEpSU92AIlQUlLi5eXlyQ5DRCRllJSUsHXr1q3uvnHksTmROMrLy6mpqUl2GCIiKcXMSkYrV1eViIhMiRKHiIhMiRKHiIhMiRKHiIhMiRKHiIhMiRKHiIhMiRKHiIhMiRKHiIhMiRKHiIhMyZx4clxS03e2HRrz2E2XLk9gJCIynFocIiIyJUocIiIyJUocIiIyJRrjkKQZbwxDRGYutThERGRKlDhERGRKlDhERGRKlDhERGRKQk0cZrbRzPaYWa2Z3T7K8Uwzeyg4vs3MyoPyYjN73Mw6zezLY1y72sx2hBm/iIi8XmiJw8wiwN3AtUAlcKOZVY6othlodffVwF3AnUF5N/AXwJ+Oce33AZ1hxC0iIuMLs8WxAah19zp37wUeBDaNqLMJuD94/QhwtZmZu3e5+xPEEshrmFke8Gng8+GFLiIiYwkzcSwFDg97fyQoG7WOu/cDbUDxBNf938DfA6fGq2Rmt5hZjZnVNDU1TSVuEREZR0oNjpvZhcAqd//hRHXd/R53r3L3qtLS0gREJyIyN4SZOI4Cy4a9LwvKRq1jZulAIdAyzjUvB6rM7ADwBLDWzH4Rp3hFRGQSwkwczwJrzKzCzKLADUD1iDrVwEeD19cDj7m7j3VBd/+quy9x93LgSuBVd39b3CMXEZExhbZWlbv3m9ltwFYgAtzn7jvN7HNAjbtXA/cCD5hZLXCCWHIBIGhVFABRM3svcI277worXhERmZxQFzl09y3AlhFlnxn2uhv4wBjnlk9w7QPAuWcdpIiITElKDY6LiEjyKXGIiMiUKHGIiMiUKHGIiMiUKHGIiMiUaOtYmbFebehgx9E2cjPTuWhZEQsKspIdkoigxCEzkLtT/eIxtu0/QWZ6Gn0Dgzxd18LNl5dTUZKb7PBE5jx1VcmM83RdC9v2n+DyVcX82W+/gT+9Zh0FWRl888n9tHT2JDs8kTlPiUNmlMaObn664zhrF+bxrvMWkxFJoygnyu9dWYFh/Gzn8WSHKDLnKXHIjLJ1ZwMZkTTed3EZZnamvDA7g7euK2XnsXbqmrSHl0gyKXHIjNHY3s3u+nYuX1VMQVbG645fubqEwuwMfvGq9lcRSSYlDpkxfl3bTEbEuGzl6Ht5ZUTSqFoxj32NnRxpHXcfLxEJkRKHzAidPf1sP3SSi5fPIy9z7Ml+Fy+fhwPff27k1i4ikihKHDIj7DjaxoA7Gyrmj1tvXm6UVaW5fO+5wwwOjrl1i4iESM9xyIzw0pGTlOZnsmgSD/ldvHwe33vuCF/82SssL379cx03Xbo8jBBFJKAWhyTdyVO9HGg5xQVlRa+ZSTWWdYvyMWBPg2ZXiSSDEock3ctH2wC4oKxwUvVzouksm5/Dqw0dYYYlImNQ4pCk213fweLCLIrzMid9zrpF+Rw9eZqO7r4QIxOR0ShxSFJ19w1w6EQXaxfmT+m8dUH9vequEkm4UBOHmW00sz1mVmtmt49yPNPMHgqObzOz8qC82MweN7NOM/vysPo5ZvYTM3vFzHaa2d+GGb+Eb19TJ4POlBPH4sIs8jPTebVR3VUiiRZa4jCzCHA3cC1QCdxoZpUjqm0GWt19NXAXcGdQ3g38BfCno1z679z9HOAi4AozuzaM+CUxXm3oJDM9jeXzc6Z0nplRUZrLgeYu3DUtVySRwmxxbABq3b3O3XuBB4FNI+psAu4PXj8CXG1m5u5d7v4EsQRyhrufcvfHg9e9wPNAWYj3ICFyd/Y2dLCqNI9I2sSzqUZaMT+H9u5+Tp7WOIdIIoWZOJYCh4e9PxKUjVrH3fuBNmD09SZGMLMi4N3Ao2Mcv8XMasyspqlJaxvNRC2dvZw83ceahXnTOn9F8AzHwRYtPyKSSCk5OG5m6cB3gX9y97rR6rj7Pe5e5e5VpaWliQ1QJuVASxcAK0umlzgWFWaRmZ7GweA6IpIYYSaOo8CyYe/LgrJR6wTJoBBomcS17wH2uvs/xCFOSZIDLV3kRiOU5EWndX6aGcvn56jFIZJgYSaOZ4E1ZlZhZlHgBqB6RJ1q4KPB6+uBx3yCkU4z+zyxBPPHcY5XEuxAyylWFOdO6mnxsSwvzqGhvZvuvoE4RiYi4wktcQRjFrcBW4HdwMPuvtPMPmdm7wmq3QsUm1kt8GngzJRdMzsAfAn4XTM7YmaVZlYG/DmxWVrPm9l2M/t4WPcg4Wlo7+ZEVy/lZ7mH+Ir5uThwWMusiyRMqIscuvsWYMuIss8Me90NfGCMc8vHuOz0/3sqM8azB04AUF48tWm4Iy0pii2KWH+ymzULpvYsiIhMT0oOjkvqe3b/CaLpaSwuzD6r6+RE05mXk8HRk6fjFJmITESJQ5Ji++GTlBVlT+v5jZGWFGVzTIlDJGGUOCThevoH2FXfTtm8s2ttDFlalE1LV68GyEUSRIlDEu6V+g76Bpyl885ufGPIkqJYAlKrQyQxlDgk4V46chIgbi2OxYWxAXIlDpHEUOKQhHvxSBsleVGKsjPicr38rAwKstI1QC6SIEocknAvHj7J+ZPcJnayFhdmc7y9e+KKInLWlDgkoTp7+qlt6uT8SW4TO1mLCrNo6uihf3AwrtcVkddT4pCE2nWsHXfinjgWFmQy6LEVd0UkXEocklC7jrUBsH5JvBNHbIC8Qd1VIqFT4pCE2l3fwfzcKAvyM+N63dK8TNIMjXOIJIAShyTUrvp2KhcXxHVgHCA9kkZxXiYN7T1xva6IvJ4ShyRM38Agexo6qFxSEMr1FxZkqatKJAGUOCRh6pq66O0fpHJxWIkjk9auXk719odyfRGJUeKQhNld3w4QXosjPwsH9jZ0hnJ9EYlR4pCE2VXfTjQ9jZVnuXnTWBYUxAbc9zUpcYiESYlDEmZ3fTtrF+aRHgnn125+bpQ0i3WJiUh4lDgkYV453sE5i8LppgJIT0tjXk6U/c1KHCJhCjVxmNlGM9tjZrVmdvsoxzPN7KHg+DYzKw/Ki83scTPrNLMvjzjnEjN7OTjnnyze8zolFCe6emnq6GHdwnC3dy3Jy1RXlUjIQkscZhYB7gauBSqBG82sckS1zUCru68G7gLuDMq7gb8A/nSUS38V+H1gTfC1Mf7RS7y92tABwNpF4SaO0vxMDrR0MTjoof4ckbkszBbHBqDW3evcvRd4ENg0os4m4P7g9SPA1WZm7t7l7k8QSyBnmNlioMDdn3Z3B74FvDfEe5A4GUociWhxdPcNcqxNS6yLhCXMxLEUODzs/ZGgbNQ67t4PtAHFE1zzyATXlBloz/EOCrLSWVgQ36VGRirJiwIaIBcJ06wdHDezW8ysxsxqmpqakh3OnPdqQwfrFuXHfamRkUqCNbA0QC4SnjATx1Fg2bD3ZUHZqHXMLB0oBFomuGbZBNcEwN3vcfcqd68qLS2dYugST+7OnuMdrA25mwogPzOdvMx06jRALhKaMBPHs8AaM6swsyhwA1A9ok418NHg9fXAY8HYxajcvR5oN7PLgtlUNwP/Fv/QJZ4a2nto7+5nXcgD4wBmxsrSXOrU4hAJTXpYF3b3fjO7DdgKRID73H2nmX0OqHH3auBe4AEzqwVOEEsuAJjZAaAAiJrZe4Fr3H0X8IfAN4Fs4KfBl8xge4KB8TULwk8cACtLcnn2QGtCfpbIXBRa4gBw9y3AlhFlnxn2uhv4wBjnlo9RXgOcG78oJWz7GmPdRmsW5iXk51WU5PGj7cfo7hsgKyOSkJ8pMpeEmjhEvrPtED/bcZzsjAhbdxwPfXAcYGVpbC2s/c1dvCGklXhF5rJZO6tKZo6mzh5K8zMTkjTgPxOHpuSKhEOJQ0LX2BFLHIlSUTKUODSzSiQMShwSqlO9/XT19Md9j/Hx5ETTWVyYpZlVIiFR4pBQNXXE9gAvzUtc4gA0JVckREocEqoziSOBLQ6AlSV51DV1Ms5jQSIyTUocEqqmjh7S04x5udGE/tyVpbl0dPfT3Nmb0J8rMhcocUiomjp7KMnLJC3B26asLI09M6IBcpH4U+KQUCV6RtWQoX3ND7RonEMk3iaVOMzsB2Z2nZkp0cikdfcN0NrVm5TEsbgwi4yIcaDlVMJ/tshsN9lE8BXgJmCvmf2tma0LMSaZJQ60dOEkfmAcID2SxrJ5ORxS4hCJu0klDnf/ubt/CLgYOAD83MyeNLOPmVlGmAFK6qoN1qhK9FTcISuKc9RVJRKCSa9VZWbFwIeBjwAvAN8GriS2LPrbwghOUtu+xi6M2HauifSdbYcA6O4bpLaxk28/ffDMcic3Xbo8obGIzEaTShxm9kNgHfAA8O5gXwyAh8ysJqzgJLXVNnVSlJNBND05Q2PFeVF6+gfp6h0gL1PreYrEy2T/Nn09WCL9DDPLdPced68KIS6ZBfY1diZlfGNIcfDsSEtnjxKHSBxN9r+Cnx+l7Kl4BiKzy+CgU9fcmbTxDYDi3NjPbunSQ4Ai8TTuf8PMbBGwFMg2s4uAoae4CoCckGOTFHb05Gm6+wZZkJ+VtBiKcjMwoEVPj4vE1UTt93cCvwuUAV8aVt4B/FlIMcksUBs8sZ3Mrqr0tDSKcjJo6epJWgwis9G4icPd7wfuN7P3u/v3ExSTzAJD28UmM3EAFOdlckJdVSJxNe4Yh5l9OHhZbmafHvk10cXNbKOZ7TGzWjO7fZTjmWb2UHB8m5mVDzt2R1C+x8zeOaz8U2a208x2mNl3zSx5fSEypn1NnczPjZKb5EHp4tyouqpE4myiwfHc4HsekD/K15jMLALcDVwLVAI3mlnliGqbgVZ3Xw3cBdwZnFsJ3ACsBzYCXzGziJktBf4IqHL3c4FIUE9mmNrGTlaV5k5cMWTFuVFO9w1wqrc/2aGIzBoTdVV9Lfj+V9O49gag1t3rAMzsQWATsGtYnU3AZ4PXjwBfttiTWpuAB929B9hvZrXB9Q4FMWebWR+xAfpj04hNQravqYt3rl+Y7DAoDmZ1nejqJSeqKbki8TDZRQ6/aGYFZpZhZo+aWdOwbqyxLAUOD3t/JCgbtY679wNtQPFY57r7UeDviCWQeqDN3f9jjJhvMbMaM6tpamqazG1KnJzo6uVEVy+rgqXNk2n+mWc51F0lEi+TfY7jGndvB95FbK2q1cB/DyuosZjZPGKtkQpgCZA7VgJz93vcvcrdq0pLSxMZ5py3L5hRtWrBDEocmlklEjeTTRxDbfzrgO+5e9skzjkKLBv2viwoG7WOmaUDhUDLOOe+Hdjv7k3u3gf8AHjTJO9BEmRoccPVM6DFkRFJozA7Qy0OkTiabOL4sZm9AlwCPGpmpUD3BOc8C6wxswozixIbxK4eUaea2CKJANcDj3lsk+hq4IZg1lUFsAZ4hlgX1WVmlhOMhVwN7J7kPUiC7GvsJDM9jaVF2ckOBYi1OvT0uEj8TGq00N1vN7MvEhtTGDCzLmJdRuOd029mtwFbic1+us/dd5rZ54Aad68G7gUeCAa/TxDMkArqPUxsIL0fuNXdB4BtZvYI8HxQ/gJwz9RvW8JU29TJytI80tISu13sWIpzo+w+3pHsMERmjalMMzmH2PMcw8/51ngnBAsjbhlR9plhr7uBD4xx7heAL4xS/pfAX04+bEm0fU2dXLhsXrLDOKM4L5Ounla6+waSHYrIrDDZZdUfAFYB24Ghv33OBIlD5p7uvgGOtJ7m/ReXJTuUM4ZWydUT5CLxMdkWRxVQGYw/iIyprqkLd1g9A2ZUDSnOG5pZpcQhEg+THRzfASwKMxCZHYYWN5xJiWNoSu6JTk3JFYmHybY4SoBdZvYMcOZvn7u/J5SoJGXta+wkzaC8OPnLjQzJTI+Qn5muFodInEw2cXw2zCBk9qht6mTZ/ByyMiLJDuU1NCVXJH4mOx33l2a2Aljj7j83sxxiU2xFXmNfY+eMWGpkpOK86JkHE0Xk7Ex2rarfJ7YI4deCoqXAj8IKSlLTwKBT19w1o8Y3hszPzaS9u5/TvZqSK3K2Jjs4fitwBdAO4O57gQVhBSWp6UjrKXr7B2fEcuojDc2sOnTiVJIjEUl9kx3j6HH33tgqH2fWldLUXAHgO9sOAfDK8XYgNiV3qGymGHqW40BLF+sWjbuVjIhMYLItjl+a2Z8R2wfjHcD3gH8PLyxJRY3tsQl3C/Jn3qaMxbmxfTkOtnQlORKR1DfZxHE70AS8DPwBsWVE/ldYQUlqamjvpiArnezozJs3kR2NkBONcKBFXVUiZ2uys6oGzexHwI/cXbsiyagaO3pYUDDzWhtDinOjanGIxMG4LQ6L+ayZNQN7gD3B7n+fGe88mXsG3Wns6GZhfmayQxlTcV4mB5rV4hA5WxN1VX2K2GyqN7r7fHefD1wKXGFmnwo9OkkZrV299A34jG5xzM+NUt92mp5+TckVORsTJY6PADe6+/6hAnevAz4M3BxmYJJaGjtiA+MLZ3DiKM6NMuhwpPV0skMRSWkTJY4Md28eWRiMc2SEE5Kkoob22IaQC2ZyV1UwJVfjHCJnZ6LEMd7iPlr4R85o7OihMDtjxq1RNdz8vFhS0ziHyNmZaFbVBWbWPkq5ATO3T0ISrqG9m4UFM7e1AZAbja2SqxaHyNkZN3G4+8z976PMGIPuNHX0sHoGLm44nJmxoiRHz3KInKXJPgA4LWa20cz2mFmtmd0+yvFMM3soOL7NzMqHHbsjKN9jZu8cVl5kZo+Y2StmttvMLg/zHmRiJzp76R+c2TOqhqwozlWLQ+QshZY4zCwC3A1cC1QCN5pZ5Yhqm4FWd18N3AXcGZxbCdwArAc2Al8Jrgfwj8DP3P0c4AJgd1j3IJNzPBgYn+ldVQDlxTkcaT1N38BgskMRSVlhtjg2ALXuXufuvcCDwKYRdTYB9wevHwGutthKipuAB929J5gKXAtsMLNC4C3AvQDu3uvuJ0O8B5mExo6hGVWp0eLoH3SOndSUXJHpCjNxLAUOD3t/JCgbtY679wNtQPE451YQWzPrX8zsBTP7hpmNuoa3md1iZjVmVtPUpFVSwtTQ3sO8nAyi6aH2fMbF0Ja2GucQmb6Z/zf9tdKBi4GvuvtFQBexBRhfx93vcfcqd68qLS1NZIxzTmNH94x+8G+48uIcQM9yiJyNMBPHUWDZsPdlQdmodYI9PgqBlnHOPQIccfdtQfkjxBKJJEnfwCDNHb0p0U0FUJqfSW40Ql2TEofIdIWZOJ4F1phZhZlFiQ12V4+oUw18NHh9PfCYu3tQfkMw66oCWAM84+7HgcNmti4452pgV4j3IBM40NzFgHtKDIxDbEruytI89jVp/3GR6ZrsDoBT5u79ZnYbsBWIAPe5+04z+xxQ4+7VxAa5HzCzWuAEseRCUO9hYkmhH7jV3YdWpvsE8O0gGdUBHwvrHmRirzbE/gFOla4qgJWludQcaE12GCIpK7TEAeDuW4ht+jS87DPDXncDHxjj3C8AXxilfDtQFd9IZbpeOd5OmsW6gFLFypI8ql88xunegRm56ZTITJdqg+Myw+w81k5JXiYZkdT5VVpZmos77G/WOIfIdKTO33aZkXYea2NJUXayw5iSVcHSKHXNGucQmQ4lDpm25s4eGtp7WFKYOuMbABUlsWc5NLNKZHqUOGTadh2LLZy8OMVaHNnRCEuLsqnTzCqRaVHikGnbOZQ4UqzFAbFxjjqNcYhMixKHTNvOY20sLcomJxrq5LxQrCrNY19jJ7HHhkRkKpQ4ZNp21bdTuaQg2WFMy6oFeXT1DlDf1p3sUERSjhKHTEtHdx/7m7s4d0lhskOZlrULYjOr9jR0JDkSkdSjxCHT8vKRNtzhwuVFyQ5lWtYuzAdgrxKHyJQpcci0vHA4tg3KBWWp2eKYlxulJC/zzJIpIjJ5ShwyLS8ePklFSS5FOdFkhzJtaxfmqcUhMg1KHDJl7s72wye5cFlqdlMNWbswn72NnQwOamaVyFQocciUHW/vprGjJ2W7qYasWZjHqd4BjmobWZEpUeKQKdt+KDa+ceHyeUmO5OycGSBvVHeVyFQocciUPX+olWh6Gm9YnJ/sUM7K2gWx+DVALjI1ShwyZdv2n+DCZUVkpqf2XhaFORksKcw6s+aWiEyOEodMSWdPPzuOtnFZxfxkhxIXlUsK2FWvxCEyFUocMiU1B04w6LChojjZocRF5ZJC6po6Od07MHFlEQGUOGSKtu0/QXqacfGK1J6KO2T9kgIGHXYfV6tDZLJCTRxmttHM9phZrZndPsrxTDN7KDi+zczKhx27IyjfY2bvHHFexMxeMLMfhxm/vN4z+09wfllhSq6IO5rKxbFFGjXOITJ5oSUOM4sAdwPXApXAjWZWOaLaZqDV3VcDdwF3BudWAjcA64GNwFeC6w35JLA7rNhldF09/bx05OSs6aYCKJuXTWF2xpm9RURkYmG2ODYAte5e5+69wIPAphF1NgH3B68fAa42MwvKH3T3HnffD9QG18PMyoDrgG+EGLuM4je1zfQNOG9dW5rsUOLGzKhcXMCuY23JDkUkZYSZOJYCh4e9PxKUjVrH3fuBNqB4gnP/AfgfwOB4P9zMbjGzGjOraWpqmu49yDCP72kiLzOdqvLUfvBvpMolBbxyvIO+gXF/pUQkkFKD42b2LqDR3Z+bqK673+PuVe5eVVo6e/6HnCzuzi/2NHLl6hIyIin1azOh88sK6ekfZM9xPUEuMhlh/gtwFFg27H1ZUDZqHTNLBwqBlnHOvQJ4j5kdINb1dZWZ/WsYwctr7WnooL6tm986Z/Yl4YuDpVOeP9Sa5EhEUkOYieNZYI2ZVZhZlNhgd/WIOtXAR4PX1wOPeWwT6GrghmDWVQWwBnjG3e9w9zJ3Lw+u95i7fzjEe5DAY680AvC2dQuSHEn8lc3LZkF+Js8fVOIQmYzQ5lS6e7+Z3QZsBSLAfe6+08w+B9S4ezVwL/CAmdUCJ4glA4J6DwO7gH7gVnfXE1pJ9JOX6rmgrJCFBVnJDiXuzIyLl8/j+WDxRhEZX6iT8d19C7BlRNlnhr3uBj4wxrlfAL4wzrV/AfwiHnHK+PY1dbLzWDv/67o3JDuU0Fy8ooif7TxOc2cPJXmZyQ5HZEabXaOcEorq7ccwg3dfsCTZoYTmzDiHuqtEJjQ7Hv+V0Lg7//7SMcqLc3l0d2OywwnNuUsLyYgYzx1s5Zr1i5IdjsiMphaHjOu5g63UNXVxYdnsWJtqLFkZES5aPo/f7GtOdigiM54Sh4zr/qcOkp+VzvnLUnub2Ml48+oSdh5r50RXb7JDEZnRlDhkTI3t3fz05Xp+p2pZym/aNBlXrinBPba0ioiMTWMcMqZ/ffog/YPORy5bwZP7WpIdTlx8Z9uhMY998I3LKMhK54m9zbN6IoDI2VKLQ0Z18lQv//KbA1xTuZDyktxkh5MQkTTjTatKeKK2mdhzqCIyGiUOGdXXf11HZ28/n75mbbJDSai3rC3l6MnT7GnQulUiY1HikNdp7OjmX35zgOvOW8w5iwqSHU5CvaNyIWkWe1JeREanMY45Zrw+/psuXQ7AX/9kN/0Dzp9csy5RYc0YpfmZXL6qmB+/VM+n37GW2PYwIjKcWhzyGk/ta+FH24/xB29dScUcGdsY6V3nL2F/cxe76rUroMholDjkjFO9/fzZD1+mbF42f/i21ckOJ2neuX4RkTSj+sVjyQ5FZEZS4pAz7vzpK+xv7uKL159PdnT2P7cxlvm5Ud7+hgU8/Oxhuvu0KLPISEocAkBtYyf3P3WQj11RzptWlSQ7nKT7vSsqaD3Vxw+eH7n3mIgocQjdfQN8//kjrCzN5X9uPCfZ4cwIGyrms35JAff9Zr+e6RAZQYlD+MnL9bSf7uPvP3ABWRlzt4tqODPj42+uoLaxU2MdIiMoccxxtY2dPHewlbesLeWiYE8KiXnPBUs5d2kBf7PlFU719ic7HJEZQ89xzGG9/YP88IUjlORFueqcBeM+4zEXRdKMz757Pdf/81P846N7uePa2bsDoshUqMUxh/18dwOtp/p470VLyYjoV2E0VeXzueGNy/jaL+t4dHdDssMRmRFC/dfCzDaa2R4zqzWz20c5nmlmDwXHt5lZ+bBjdwTle8zsnUHZMjN73Mx2mdlOM/tkmPHPZkdaT/Gb2mbeWD6flSV5yQ5nRvvse9Zz7tIC/vih7ezWQ4Ei4SUOM4sAdwPXApXAjWZWOaLaZqDV3VcDdwF3BudWAjcA64GNwFeC6/UDf+LulcBlwK2jXFMmMOjOj7YfJS8rnY3aJnVCWRkRvvqhS8jLTOfGrz/Ni4dPJjskkaQKc4xjA1Dr7nUAZvYgsAnYNazOJuCzwetHgC9bbHGgTcCD7t4D7DezWmCDuz8F1AO4e4eZ7QaWjrimTOCFQ60cO9nN71Qtm9MP+o000RjPhy5dwb1P1PH+rz7Jb5+3mEsr5p9Zy2ponS+RuSDMrqqlwOFh748EZaPWcfd+oA0onsy5QbfWRcC20X64md1iZjVmVtPU1DTtm5htevoH+I9dDSybl80FZbN/O9h4mp8b5b+9bTUrS3OpfvEY33nmEKd79WS5zD0pOSJqZnnA94E/dvdRO53d/R53r3L3qtLS0sQGOIM9ta+Fju5+rjtvsVZ+nYa8zHRuvrycjesXsbu+nf/72F7qmjuTHZZIQoWZOI4Cy4a9LwvKRq1jZulAIdAy3rlmlkEsaXzb3X8QSuSzVHt3H7/e28w5i/JZXjw3V76NhzQz3rK2lD94yyoiaca9v97P32zZTU+/Wh8yN4SZOJ4F1phZhZlFiYNodNIAAAypSURBVA12V4+oUw18NHh9PfCYx9Z3qAZuCGZdVQBrgGeC8Y97gd3u/qUQY5+V7ntiP6f7Bnj7GxYmO5RZYdn8HG67ajVV5fP52q9iYx9HT55OdlgioQstcQRjFrcBW4HdwMPuvtPMPmdm7wmq3QsUB4PfnwZuD87dCTxMbND7Z8Ct7j4AXAF8BLjKzLYHX78d1j3MJm2n+rj31/upXFzAkqLsZIcza2SmR/gvFy3l6zdXcbD5FJu+/ATPHTyR7LBEQmVzYQG3qqoqr6mpSXYYSfX3/7GH//tYLZ+4ajWLC5U44u2mS5dT29jB5vtrqD/Zzd+87zzef0lZssMSOStm9py7V40sT8nBcZma1q5e7ntiP9edt1hJI0SrF+Tzb7deQVX5PP7key9y/5MHkh2SSCi0VtUc8LVf1XGqb4BPvn0NNQdakx3OrDT8GZCN6xfReqqPv6zeybb9J7hy9dj7m+j5D0lFanHMcs2dPdz/5AHec8ES1i7MT3Y4c0J6JI2bNizn3KWFbHm5nl++queIZHZRi2OW+9ov99HTP8AfXb0m2aHMKZE044NVy4gYbN15nPQ044pxWh4iqUSJYxY73tbNt546yHsvWsqqUi1kmGiRNOP6S5bRP+j85OV6oulpvLF8frLDEjlr6qqaxf7x0b0MuvOpt69NdihzViTN+OAbl7F2YR4/euGoFkiUWUEtjiQab1G9sx003dfUycM1h/nIZStYNj/nrK4lZyc9LY0PXbqCbz55gO89d5iMSBqVSwqSHZbItKnFMUt96T9eJTM9jVt/a3WyQxEgI5LGzZetYGlRNt999hB7GzuSHZLItClxzEIvHTnJT16u5+NvXklpfmayw5FAZkaE331TBQvyM/nXpw+yv7kr2SGJTIsSxyzj7nzxZ3uYl5PB77+5ItnhyAjZ0Qgfu6KCwuwo33rqAC8d0ZiHpB4ljlnmpzuO80RtM5+4ag35WRnJDkdGkZeZzuYrK8iJRrj5vmfYc1zdVpJalDhmkY7uPv7q33dSubiAmy9fkexwZByF2RlsvnIlmelpfOgb29RtJSlFiWMW+fyPd9PY0cNfv+880iP6o53p5udG+fbHL2XQnQ99/Wn2NqjlIalB/7rMEv/+4jEeqjnMf3vrKi5cVpTscGSSVi/I54HNG+gdcN73lSd5fE9jskMSmZCe40iSnv4BBgadSNrZb9+681gbd/zgZS5aXsTiwuxxnw+RmWf9kkKqb7uCzffXsPmbz/Ln11Xye1eUa2tfmbGUOBKkvu00333mME/WNvPK8Q46e/oByIlGWFqUzZoFeZy/rIiCKQ5oH2zp4nf/5Vnys9K5+6aL+cUeLaiXipYUZfPIf72cTz20nf/9411sq2vhr993HiV5mk4tM48SR8heONTKfb85wJaX63F3LlxWxPWXlFGSF+WFQydpO93HoROn2LLjOD/dcZzVC/K4aHkR77t4KVkZkXGv/XRdC3/47ecZdOc7H79cO/uluNzMdP75w5dw7xP7+T9b93DV3/2CT1y1hpvftILM9PF/F0QSSYkjBH0Dg/xsx3Hu+81+Xjh0kvzMdH7vinJuvrz8Nct/DO9Sauzo5sXDJ9l++CQP1xzhpzuOs+nCJWy6cCkXLisiIxjsdnf2NXXx9V/V8b3nDlNekss3bq5ipRYxnBXS0ozff8tK3raulM//ZDdf2LKbB54+yKffsZZrz1ukBCIzgraOjaOWzh4erjnCt546QH1bN+XFOXzsigref0kZeZmvz9GjjUUMurO/uYsTXb1sebmenv5BsjMirCjOITsaobG9h6MnT5MRMW6+vJxPvn3Na7q3NL6RWsZbk+w72w7xakMHP91RT0N7D7nRCFXl86laMY9PaJn8lBLmunRhGmvr2FBbHGa2EfhHIAJ8w93/dsTxTOBbwCVAC/BBdz8QHLsD2AwMAH/k7lsnc81Ea+/u4/FXGvnRC0f59d5m+gedK1eX8Pn3nstvrVtA2hQHv9PMWFWax1+8azl/tWk9T9Y2s23/CQ6fOE133wAXr8jhv751JW+vXKhtYOeAtQvzWb0gj9rGTrbtP8GvXm3il6828cPtR7lq3QKuXFPC+WVFzM+NJjtUGYe709M/SNvpPtpP99HZ00/vwCB9A07b6T4y09PIjkbIiUZYkJ/FosIsFhVkkR2dmS3M0BKHmUWAu4F3AEeAZ82s2t13Dau2GWh199VmdgNwJ/BBM6sEbgDWA0uAn5vZ0NrgE10zbgYHnVN9A5zq7edUzwAtXb0cb+umvu00rzZ08MKhk9Q2deIOSwqz+PibV/K+i5fGbae9gqwMNp67mI3nLo7L9SQ1pZmxdmE+axfmc/JUL7vq22k73ce3njrIN57YD8DSomzesLiAZfOzKZuXw5LCLAqyM8jPSqcgK/Y9MyNCxIxIWuwrzdDMrQm4O4Me++7EegSGOml6+gc51dtPV88Ap3sH6Ojpo7mzl6aOHho7umPf23uobzvN4dbT9PYPjvoztrxcP+bPL8hKZ1FhFgsLsliQn8XCgkwWFsS+z8/NJDczQm40nZzMCDnRdDIiRnpaWuh/tmG2ODYAte5eB2BmDwKbgOH/yG8CPhu8fgT4ssXudhPwoLv3APvNrDa4HpO4Zty8/a5fUtc0+hO983IyuGj5PN59wRIuW1lM1Yp5U25diExVUU6UN60q4aZLl9PV08+Lh0/y0tE2Xj7axt6GDp7c18yp3oFJXy+SZkTMSEsDIzm/v8nKXUNJwAkSw7DXg2fZgx+NpFGan0lpfibrFuWzsCCLwuwMCrIzKMzKIC8rnWh6GtFIGjduWE5P/wCn+wbo6umnob2H423dHG/vpuHMVw/7Gptp7Oihf5LBpacZaWnGS395zYQTbaYqzMSxFDg87P0R4NKx6rh7v5m1AcVB+dMjzl0avJ7omgCY2S3ALcHbTjPbM417GNNBYPvZX6YEaB7twIfO/tqpYMz7nwNKgObp/jnPgt+PWf9nv3f8w2fuf3PIcWR/YdqnjvnnM2tnVbn7PcA9yY5jPGZWM9rA01wxl+9/Lt876P5T/f7DXHLkKLBs2PuyoGzUOmaWDhQSGyQf69zJXFNEREIUZuJ4FlhjZhVmFiU22F09ok418NHg9fXAYx6bH1wN3GBmmWZWAawBnpnkNUVEJEShdVUFYxa3AVuJTZ29z913mtnngBp3rwbuBR4IBr9PEEsEBPUeJjbo3Q/c6u4DAKNdM6x7SIAZ3ZWWAHP5/ufyvYPuP6Xvf048ACgiIvGjZdVFRGRKlDhERGRKlDiSwMw2mtkeM6s1s9uTHU8YzOw+M2s0sx3Dyuab2f8zs73B93lBuZnZPwWfx0tmdnHyIo8PM1tmZo+b2S4z22lmnwzKZ/1nYGZZZvaMmb0Y3PtfBeUVZrYtuMeHggkuBJNgHgrKt5lZeTLjjxczi5jZC2b24+D9rLl/JY4EG7YUy7VAJXBjsMTKbPNNYOOIstuBR919DfBo8B5in8Wa4OsW4KsJijFM/cCfuHslcBlwa/DnPBc+gx7gKne/ALgQ2GhmlxFbUugud18NtPKfz76dWXoIuCuoNxt8Etg97P2suX8ljsQ7sxSLu/cCQ8umzCru/itiM+WG2wTcH7y+H3jvsPJveczTQJGZpfQCXe5e7+7PB687iP0DspQ58BkE99AZvM0Ivhy4itjSQvD6ex/6TB4BrrYUX0TLzMqA64BvBO+NWXT/ShyJN9pSLEvHqDvbLHT3oRXdjgMLg9ez+jMJuh4uArYxRz6DoJtmO9AI/D9gH3DS3fuDKsPv7zVLDwFDSw+lsn8A/gcwtLJhMbPo/pU4JCmCBz1n/VxwM8sDvg/8sbu3Dz82mz8Ddx9w9wuJre6wATgnySEljJm9C2h09+eSHUtYlDgSby4vm9Iw1P0SfG8MymflZ2JmGcSSxrfd/QdB8Zz6DNz9JPA4cDmx7rehh46H399YSw+lqiuA95jZAWJd0VcR20No1ty/EkfizeVlU4YvMfNR4N+Gld8czCy6DGgb1p2TkoI+6nuB3e7+pWGHZv1nYGalZlYUvM4mtn/ObmIJ5Pqg2sh7H23poZTk7ne4e5m7lxP7+/2Yu3+I2XT/sXXo9ZXIL+C3gVeJ9fv+ebLjCekevwvUA33E+nM3E+u3fZTYitM/B+YHdY3YTLN9wMtAVbLjj8P9X0msG+olYivwbw/+3Gf9ZwCcD7wQ3PsO4DNB+Upia87VAt8DMoPyrOB9bXB8ZbLvIY6fxduAH8+2+9eSIyIiMiXqqhIRkSlR4hARkSlR4hARkSlR4hARkSlR4hARkSlR4hARkSlR4hARkSn5/57d5KepI97PAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMml12FJGjPW"
      },
      "source": [
        "# GPT2 Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANJhbBwdxN-b"
      },
      "source": [
        "\n",
        "Special tokens are specified following orignal scripts.\n",
        "\n",
        "Models are Finnish GPT2 from the following project.\n",
        "https://huggingface.co/Finnish-NLP/gpt2-finnish?text=Teksti%C3%A4+tuottava+teko%C3%A4ly+on\n",
        "\n",
        "Note that the medium and large models were too big for free co-lab version, so I couldn't check them out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33b83031-922d-43b3-b423-42f157a91b05"
      },
      "source": [
        "# Load the GPT tokenizer.\n",
        "model_name='Finnish-NLP/gpt2-finnish'\n",
        "#model_name='Finnish-NLP/gpt2-medium-finnish'\n",
        "#model_name='Finnish-NLP/gpt2-large-finnish'\n",
        "if flag_train_model:\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(model_name, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n",
        "\n",
        "if flag_run_orig_model:\n",
        "  tokenizer_orig = GPT2Tokenizer.from_pretrained(model_name, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh0XKuDvnryn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37304642-face-43f2-b7ba-a0f6a5547283"
      },
      "source": [
        "if flag_train_model:\n",
        "  print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
        "  print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
        "  print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
        "  print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The max model length is 1000000000000000019884624838656 for this model, although the actual embedding size for GPT small is 768\n",
            "The beginning of sequence token <|startoftext|> token has the id 50257\n",
            "The end of sequence token <|endoftext|> has the id 50256\n",
            "The padding token <|pad|> has the id 50258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# PyTorch Datasets & Dataloaders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lgZoOYkxZfx"
      },
      "source": [
        "Using batch size 2 as the original script. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scqrzmqhV__z"
      },
      "source": [
        "batch_size = 2"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_XJVIetKN-h"
      },
      "source": [
        "class GPT2Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for txt in txt_list:\n",
        "\n",
        "      encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx] "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Z7aYUgpWrd"
      },
      "source": [
        "Padding settings are directly from the original script. May not be optimal for this use case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xza_O1_rD7yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313068ae-c36b-4282-dfc5-36730c006ec8"
      },
      "source": [
        "if flag_train_model:\n",
        "  dataset = GPT2Dataset(all_text, tokenizer, max_length=768)\n",
        "\n",
        "  # Split into training and validation sets\n",
        "  train_size = int(0.9 * len(dataset))\n",
        "  val_size = len(dataset) - train_size\n",
        "\n",
        "  train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "  print('{:>5,} training samples'.format(train_size))\n",
        "  print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  273 training samples\n",
            "   31 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0WeP5PREUuy"
      },
      "source": [
        "if flag_train_model:\n",
        "  # Create the DataLoaders for our training and validation datasets.\n",
        "  # We'll take training samples in random order. \n",
        "  train_dataloader = DataLoader(\n",
        "              train_dataset,  # The training samples.\n",
        "              sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "              batch_size = batch_size # Trains with this batch size.\n",
        "          )\n",
        "\n",
        "  # For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "  validation_dataloader = DataLoader(\n",
        "              val_dataset, # The validation samples.\n",
        "              sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "              batch_size = batch_size # Evaluate with this batch size.\n",
        "          )"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "# Finetune GPT2 Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "def configure_model(model_name, tokenizer):\n",
        "  # I'm not really doing anything with the config buheret\n",
        "  configuration = GPT2Config.from_pretrained(model_name, output_hidden_states=False)\n",
        "\n",
        "  # instantiate the model\n",
        "  model = GPT2LMHeadModel.from_pretrained(model_name, config=configuration)\n",
        "\n",
        "  # this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
        "  # otherwise the tokenizer and model tensors won't match up\n",
        "  model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "  # Tell pytorch to run this model on the GPU.\n",
        "  model.cuda()\n",
        "  return model\n",
        "\n",
        "\n",
        "if flag_train_model:\n",
        "\n",
        "  model=configure_model(model_name, tokenizer)\n",
        "\n",
        "  # Set the seed value all over the place to make this reproducible.\n",
        "  seed_val = 42\n",
        "\n",
        "  random.seed(seed_val)\n",
        "  np.random.seed(seed_val)\n",
        "  torch.manual_seed(seed_val)\n",
        "  torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBEVY2PYSTXJ"
      },
      "source": [
        "# some parameters from original script, may not be optimal\n",
        "\n",
        "epochs = 5\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 100"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "307dfe9c-f613-4f2c-8bd9-c953eb7e284c"
      },
      "source": [
        "if flag_train_model:\n",
        "  # Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "  optimizer = AdamW(model.parameters(),\n",
        "                    lr = learning_rate,\n",
        "                    eps = epsilon\n",
        "                  )"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "if flag_train_model:\n",
        "  # Total number of training steps is [number of batches] x [number of epochs]. \n",
        "  # (Note that this is not the same as the number of training samples).\n",
        "  total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "  # Create the learning rate scheduler.\n",
        "  # This changes the learning rate as the training loop progresses\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps = warmup_steps, \n",
        "                                              num_training_steps = total_steps)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCPohrZ-CTWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3958d17-511d-4209-9fd2-4aa86d1dac34"
      },
      "source": [
        "if flag_train_model:\n",
        "  torch.cuda.empty_cache()\n",
        "  total_t0 = time.time()\n",
        "\n",
        "  training_stats = []\n",
        "\n",
        "  model = model.to(device)\n",
        "\n",
        "  for epoch_i in range(0, epochs):\n",
        "\n",
        "      # ========================================\n",
        "      #               Training\n",
        "      # ========================================\n",
        "\n",
        "      print(\"\")\n",
        "      print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "      print('Training...')\n",
        "\n",
        "      t0 = time.time()\n",
        "\n",
        "      total_train_loss = 0\n",
        "\n",
        "      model.train()\n",
        "\n",
        "      for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_labels = batch[0].to(device)\n",
        "          b_masks = batch[1].to(device)\n",
        "\n",
        "          model.zero_grad()        \n",
        "\n",
        "          outputs = model(  b_input_ids,\n",
        "                            labels=b_labels, \n",
        "                            attention_mask = b_masks,\n",
        "                            token_type_ids=None\n",
        "                          )\n",
        "\n",
        "          loss = outputs[0]  \n",
        "\n",
        "          batch_loss = loss.item()\n",
        "          total_train_loss += batch_loss\n",
        "\n",
        "          # Get sample every x batches.\n",
        "          if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "              elapsed = format_time(time.time() - t0)\n",
        "              print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "              model.eval()\n",
        "\n",
        "              sample_outputs = model.generate(\n",
        "                                      bos_token_id=random.randint(1,30000),\n",
        "                                      do_sample=True,   \n",
        "                                      top_k=50, \n",
        "                                      max_length = 200,\n",
        "                                      top_p=0.95, \n",
        "                                      num_return_sequences=1\n",
        "                                  )\n",
        "              for i, sample_output in enumerate(sample_outputs):\n",
        "                    print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "              \n",
        "              model.train()\n",
        "\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "          scheduler.step()\n",
        "\n",
        "      # Calculate the average loss over all of the batches.\n",
        "      avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "      \n",
        "      # Measure how long this epoch took.\n",
        "      training_time = format_time(time.time() - t0)\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "      print(\"  Training epoch took: {:}\".format(training_time))\n",
        "          \n",
        "      # ========================================\n",
        "      #               Validation\n",
        "      # ========================================\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"Running Validation...\")\n",
        "\n",
        "      t0 = time.time()\n",
        "\n",
        "      model.eval()\n",
        "\n",
        "      total_eval_loss = 0\n",
        "      nb_eval_steps = 0\n",
        "\n",
        "      # Evaluate data for one epoch\n",
        "      for batch in validation_dataloader:\n",
        "          \n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_labels = batch[0].to(device)\n",
        "          b_masks = batch[1].to(device)\n",
        "          \n",
        "          with torch.no_grad():        \n",
        "\n",
        "              outputs  = model(b_input_ids, \n",
        "  #                            token_type_ids=None, \n",
        "                              attention_mask = b_masks,\n",
        "                              labels=b_labels)\n",
        "            \n",
        "              loss = outputs[0]  \n",
        "              \n",
        "          batch_loss = loss.item()\n",
        "          total_eval_loss += batch_loss        \n",
        "\n",
        "      avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "      \n",
        "      validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "      print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "      print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "      # Record all statistics from this epoch.\n",
        "      training_stats.append(\n",
        "          {\n",
        "              'epoch': epoch_i + 1,\n",
        "              'Training Loss': avg_train_loss,\n",
        "              'Valid. Loss': avg_val_loss,\n",
        "              'Training Time': training_time,\n",
        "              'Validation Time': validation_time\n",
        "          }\n",
        "      )\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Training complete!\")\n",
        "  print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    137. Loss: 2.057128667831421.   Elapsed: 0:00:55.\n",
            "0:  tuottanutMaskinhan oroli jälähän jahan jannammamahan, meiristä tuli kans sitä meirän änsä oli, kuinka meillon, se tuli meille ikkii talahan meiränhän. Siinä, joka kävi siinä aina yhääki. Ei siinä olis voinu kyllä sitä sen ku sanoo, mutta se justihin keris ny se, että ei. Me meimmä, joka oli se, johon \n",
            "\n",
            "  Average training loss: 8.08\n",
            "  Training epoch took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 1.64\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    137. Loss: 1.1458570957183838.   Elapsed: 0:00:59.\n",
            "0:  laske\n",
            "\n",
            "  Average training loss: 1.52\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 1.31\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    137. Loss: 0.8930748701095581.   Elapsed: 0:00:58.\n",
            "0:  asiaKun olin koulusta kotia, niin tunsin olevani jo aivan varma siitä, että saan nimeni ja nimeni. Ja niin minä havaattin ja niin minä havaattin. Ja niin me sitte havaattinhin ja havaattinehen. Ja niin me sitte havaattinhin, kuinka isä tiätysti ja tarkasti ja tarkasti otti ja otti meitä sisaruksia ja lähärin ja sanoo, että me ei oltu tehty, kun isä lähti meirän koulun pihalle. Isä otti heti ja pani kaikki pois. Isä haki meille opettajalta, että  kumminki saisimma ne vaatteet pois. �Periaatehian ja   kumminki niin hyvin pääsi. Isä lähti siitä sitte liikkeelle ja lähti alaha, sitte lähäretteli ja sitten lähtimmä äiteen kans häntä ja notta tämä tuli kotia. Isä sai kumminki housut pois ja huipunhatulle. Nytkö jo palio voihihin. � yn. ja, notta isä haki meille opettajalta, että uta\n",
            "\n",
            "  Average training loss: 1.19\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 1.23\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    137. Loss: 1.0499677658081055.   Elapsed: 0:01:00.\n",
            "0:  säästöjä\n",
            "\n",
            "  Average training loss: 1.01\n",
            "  Training epoch took: 0:01:26\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 1.16\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    137. Loss: 0.8820787072181702.   Elapsed: 0:00:59.\n",
            "0: NytSe sanoo, että pitää ostaa ittelleski isoo trukin piänet pualehet, jos ostaa veljien kans samanmoinen pannu. Ei oo sellaasta löytyny. Kyllä sitä on ittekkin joskus osteltihin. Mulla oli ajatuksena ostaa isoo visseli ja sillä viilahalla, ku se oli nii isoo, ettei ollu oikeen sopiva peli ja ajattelin, että pitää ostaa joku iso pannu, johonki mumma tahtoo puhaltaa. _\n",
            "\n",
            "  Average training loss: 0.88\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 1.15\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:07:10 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX"
      },
      "source": [
        "if flag_train_model:\n",
        "  # Display floats with two decimal places.\n",
        "  pd.set_option('precision', 2)\n",
        "\n",
        "  # Create a DataFrame from our training statistics.\n",
        "  df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "  # Use the 'epoch' as the row index.\n",
        "  df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "  # A hack to force the column headers to wrap.\n",
        "  #df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "  # Display the table.\n",
        "  df_stats"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "48eb6b94-8057-4200-d338-06fa94cbffcd"
      },
      "source": [
        "if flag_train_model:\n",
        "  # Use plot styling from seaborn.\n",
        "  sns.set(style='darkgrid')\n",
        "\n",
        "  # Increase the plot size and font size.\n",
        "  sns.set(font_scale=1.5)\n",
        "  plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "  # Plot the learning curve.\n",
        "  plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "  plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "  # Label the plot.\n",
        "  plt.title(\"Training & Validation Loss\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfjYoa6WmkN6"
      },
      "source": [
        "# Display Model Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "586cff8c-4f75-4429-b74b-4370671dd6db"
      },
      "source": [
        "if flag_train_model:\n",
        "  # Get all of the model's parameters as a list of tuples.\n",
        "  params = list(model.named_parameters())\n",
        "\n",
        "  print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "  print('==== Embedding Layer ====\\n')\n",
        "\n",
        "  for p in params[0:2]:\n",
        "      print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "  print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "  for p in params[2:14]:\n",
        "      print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "  print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "  for p in params[-2:]:\n",
        "      print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The GPT-2 model has 148 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "transformer.wte.weight                                  (50259, 768)\n",
            "transformer.wpe.weight                                   (1024, 768)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "transformer.h.0.ln_1.weight                                   (768,)\n",
            "transformer.h.0.ln_1.bias                                     (768,)\n",
            "transformer.h.0.attn.c_attn.weight                       (768, 2304)\n",
            "transformer.h.0.attn.c_attn.bias                             (2304,)\n",
            "transformer.h.0.attn.c_proj.weight                        (768, 768)\n",
            "transformer.h.0.attn.c_proj.bias                              (768,)\n",
            "transformer.h.0.ln_2.weight                                   (768,)\n",
            "transformer.h.0.ln_2.bias                                     (768,)\n",
            "transformer.h.0.mlp.c_fc.weight                          (768, 3072)\n",
            "transformer.h.0.mlp.c_fc.bias                                (3072,)\n",
            "transformer.h.0.mlp.c_proj.weight                        (3072, 768)\n",
            "transformer.h.0.mlp.c_proj.bias                               (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "transformer.ln_f.weight                                       (768,)\n",
            "transformer.ln_f.bias                                         (768,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8"
      },
      "source": [
        "# Saving & Loading Fine-Tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba28fab0-7ce7-4a56-b6f6-ea143dd284b7"
      },
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "if flag_train_model:\n",
        "\n",
        "  # Create output directory if needed\n",
        "  if not os.path.exists(output_dir):\n",
        "      os.makedirs(output_dir)\n",
        "\n",
        "  print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "  # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "  # They can then be reloaded using `from_pretrained()`\n",
        "  model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "  model_to_save.save_pretrained(output_dir)\n",
        "  tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "  # Good practice: save your training arguments together with the trained model\n",
        "  # torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to ./model_save/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqMzI3VTCZo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88e7ecf-ee30-4f77-d793-0df2d119c353"
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 500036K\n",
            "-rw------- 1 root root      1K Nov 19 17:57 added_tokens.json\n",
            "-rw------- 1 root root      1K Nov 19 17:57 config.json\n",
            "-rw------- 1 root root    520K Nov 19 17:57 merges.txt\n",
            "-rw------- 1 root root 498441K Nov 19 17:57 pytorch_model.bin\n",
            "-rw------- 1 root root      1K Nov 19 17:57 special_tokens_map.json\n",
            "-rw------- 1 root root      1K Nov 19 17:57 tokenizer_config.json\n",
            "-rw------- 1 root root   1050K Nov 19 17:57 vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WUFUIQ8Cu8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ac6dc1-e6d0-4396-adc7-a1b8030598fd"
      },
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 487M Nov 19 17:57 ./model_save/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls $data_dir/model_save"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StfxHfIIiMJs",
        "outputId": "ef14f84d-633c-4d84-c10b-15fd184db71b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "added_tokens.json  merges.txt\t      special_tokens_map.json  vocab.json\n",
            "config.json\t   pytorch_model.bin  tokenizer_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxlZsafTC-V5"
      },
      "source": [
        "if flag_train_model:\n",
        "  # Copy the model files to a directory in your Google Drive.\n",
        "  !cp -r ./model_save/ $data_dir\n",
        "else:\n",
        "  # # Load a trained model and vocabulary that you have fine-tuned\n",
        "  !cp -r $data_dir/model_save .\n",
        "  model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
        "  model.to(device)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLf6rbRglYhQ"
      },
      "source": [
        "# Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4XhewaV93-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "540f3c5b-f339-4b78-b1e2-4368850b2479"
      },
      "source": [
        "def run_model(model, tokenizer, prompt):\n",
        "  model.eval()\n",
        "\n",
        "  prompt = \"<|startoftext|> \" + prompt\n",
        "\n",
        "  generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "  generated = generated.to(device)\n",
        "\n",
        "  print(generated)\n",
        "\n",
        "  sample_outputs = model.generate(\n",
        "                                  generated, \n",
        "                                  #bos_token_id=random.randint(1,30000),\n",
        "                                  do_sample=True,   \n",
        "                                  top_k=50, \n",
        "                                  max_length = 300,\n",
        "                                  top_p=0.9, \n",
        "                                  num_return_sequences=10\n",
        "                                  )\n",
        "\n",
        "  for i, sample_output in enumerate(sample_outputs):\n",
        "    print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "\n",
        "run_model(model, tokenizer, \"Hiano ilima! Lähretähän ulokoolemaha.\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50257,   397,   660,    83,   544,  4098,     5,  2294, 39709,   891,\n",
            "           859, 43442,  5894, 31193,    18]], device='cuda:0')\n",
            "0:  Hiano ilima! Lähretähän ulokoolemaha. Koetahan kumminki vähä tihkusateen päälle, vaikka tuskin on lämpöä. Kuivien puales söitte viäläkin suklaata, moon aina tykänny siitä, ku siältä on tullu tuanu, ku pakkas on viälä tupaa. No, kumminki on jo usiempana päivänä ollu sellaanen tilanne, notta suklaata ei ookaa enää palio.. Niin, suklaata kuluu melekeen palio, ettei se kauaakaa kestää. Silakkaa on kyllä niin palio, ettei sitä oikeen pystyny enää raakkaamahan. Mutta suklaata kuluu niin palio, ettei se kauaakaa kestä. \n",
            "\n",
            "\n",
            "1:  Hiano ilima! Lähretähän ulokoolemaha. Soon sellaanen juttu, että kannattaa ostaa sellaanen vahava vahava vaha. Meistä ei oo kumminkaa sitä laastaretta joutunu sen takia ostelemhan. Ku oot koittanu vahata, ni tee vahataki vähä vahava vahava vahava vaha. \n",
            "\n",
            "\n",
            "2:  Hiano ilima! Lähretähän ulokoolemaha. Kualahan viälä piänet tuloo tasaaset pakarat ja takapäät kiärtää jo kympillä. Äitee sanoo, notta  ����_�_������������_��_\n",
            "\n",
            "\n",
            "3:  Hiano ilima! Lähretähän ulokoolemaha. Kotoa tulles on kaks pakettia. Molimma jo väsyksis ja uuret vaattehet oli sellaaset, että niistä ei sais eres olla eres meirän vaattehia. Eritehet oli niin ilimaases ja eres meirän vaattehet, että ei viälä tarvinnu raahautua kotoota. Jokahisella meistä oli sellaaset justihin vissihin asti kuivat vaatteet päällä ja sellaaset pikkupömpöt kaulas. Niin ja olihan se hyvä, notta jaksaa viättää monta päivää kuivia vaattehia märkinä. Nukahtaminen saattaa tua viälä tuanki piänes arjen tuskas, jotenka tuskin kerkes nuaruttaa koko autoa.. \n",
            "\n",
            "\n",
            "4:  Hiano ilima! Lähretähän ulokoolemaha. �\n",
            "\n",
            "\n",
            "5:  Hiano ilima! Lähretähän ulokoolemaha. Seisoomma tasamaalla ja lähärettihin isännän kans pihalle lenkille. Kun isä kerkes sanoo, että meirän koira oli kyllä ilamanen, niin mä sitte jäin auton alle ja sitte suuntasin häntä peräs pihalle. Isä kerkes sanoa, että ”����\n",
            "\n",
            "\n",
            "6:  Hiano ilima! Lähretähän ulokoolemaha. Sateinen lauantai on aina hyvä päivä, varsinkin kun saa olla kotona viälä. Seisoothan omalla risukipalla ja keräät itsellesi keltaaset viälä kasan lehtiä. Sitte viälä meethän taas askarteluhoommahan. Tulkaahan ny kattomahan ja tehtihin askarteluhautoja. Ne on niin ikään tosi hyyjäväsiä askarteluhommia, ku voi teherä ittekkin.. \n",
            "\n",
            "\n",
            "7:  Hiano ilima! Lähretähän ulokoolemaha. Siältä se näkyy taivahallansa ja niin äiteeki, joka sen näki, niin ei sekää auttanu, ku se vaan huanotti. Me yritämmä sitä silittää, mutta se vain pomppii mun nenusta sen yli ja hyppii mun yli ja minä huurin ja huurin, ku se kontti meni rikki ja minä huurin sille, että moon mä sillä lailla kurkottamas. Me yritämmä kans leikkiä niillä eres, mutta ei ne oikeen sovi siihen kuvioon. Se sanoo, notta ”��\n",
            "\n",
            "\n",
            "8:  Hiano ilima! Lähretähän ulokoolemaha. Nukutahan yhyren kömmärin päälle, niin saat rairuakut ja akselit ojennettua. No, ei ne kauaa tarvinnu, ku isäntä laittoo kaukosäätimen ja minä jäin taas isännän kans tupahan, ku rupiaa syämähän ja viuhtoo. Aiva helevettihin, kun isäntä havahtuu, että voi kuinka se isäntä oikeen kerkes tulla. No, sitte ku emäntä havahtuu, niin isäntä hommas meille paksun annoksen kaurapuuroos, notta tämä on nyt sitte tenavien juttu. Kustulle se oli kyllä ihan tavallista, mutta niin se vaan oli, ku sen piänehen taloon asuttihin. \n",
            "\n",
            "\n",
            "9:  Hiano ilima! Lähretähän ulokoolemaha. Aiva ulukomailla asuuvana äiteen kans. Meille on tullu joulusauna, jota lämmittämäs isoo lauma lapsia. Saunasta tuli niin miälianen elämys, et en mä muista siitä mitää. Pekan perhees asuu tällä hetkellä kaks koira- ja kaksi kissanpoikaa. Sauna oli niin kutsuvas ja se herätti mun sisuskalut. Pestyä ammoota kiärtihin kiärtähän ja tuahotihin saunan taa. Pestyä ammoosta tultihin siältä, ku sinne oli isoo lauma lapsia. Sauna oli tosi rakas paikka ja siihen kuuluu niin suuri intohimo ku piänet ja imes ne tenavat. Soli kumminki niin rakas paikka, että sitä kutsuttihin mun isännäksi. \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To illustrate whether the fine tuned model improved the dialect, run the original non-adapted model for comparison. First load the original model."
      ],
      "metadata": {
        "id": "pT26_gK26Lz0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EfPFjL5myXl",
        "outputId": "672edd6e-5955-44c6-fb77-f1654ea95ef3"
      },
      "source": [
        "# Load the GPT tokenizer.\n",
        "\n",
        "if flag_run_orig_model:\n",
        "  tokenizer_orig = GPT2Tokenizer.from_pretrained(model_name, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p342QDcmkMi"
      },
      "source": [
        "if flag_run_orig_model:\n",
        "  model_orig=configure_model(model_name, tokenizer_orig)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then run the original model."
      ],
      "metadata": {
        "id": "fvAdwbmz9RZZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fcf754c-9a40-4ae7-dc51-a16eb37a4efa",
        "id": "e0DWKtforAa9"
      },
      "source": [
        "run_model(model_orig, tokenizer_orig, \"Hiano ilima! Lähretähän ulokoolemaha.\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50257,   397,   660,    83,   544,  4098,     5,  2294, 39709,   891,\n",
            "           859, 43442,  5894, 31193,    18]], device='cuda:0')\n",
            "0:  Hiano ilima! Lähretähän ulokoolemaha. Sielhä se on ollu. Linnut kaikonneet? Vuaks ne? Ai niin, nyt on sitte tuo kokkokin. Nyt on nuo jiäki, tiijjäkkö. Pyäriäkkö? Mie oon, tiiätkö? Se on miun oma ja hänen oma. Se kuuluu niin. En mää oo sellane.. Minä sanoin. Minä oon sellane. Kyllä, kyllä, kyllä, kyllä. Se kuuluu mun omaan juttuun ja on mun oma. Mie sanon sen aina kaikille.. Minä sanon, että mää annan sille.. Minä sanon, että minä voin antaa sille.. Minun täytyy antaa sille... Mie sanon, että se kuuluu sen omaan juttuun.. Minä sanon, että jos mie annan sille sen, niin se on kyllä mun oma juttu.. Mie sanon, että annan sille sen.. Mie sanon, että se kuuluu minun omaan juttuun ja on mun oma juttu. Se kuuluu minun omaan juttuun ja on mun oma. Mie sanon, että minä voin antaa sille sen.. Mie sanon, että minä voin antaa sille sen.. Mie sanon, että minä voin antaa sille sen.. Mie sanon, että minä voin antaa sille sen.. Mie sanon, että se kuuluu minun omaan juttuun ja on mun oma juttu. Mie sanon, että jos mie annan sille sen, niin se on kyllä mun oma juttu. Mie sanon, että kyllä, kyllä, kyllä, kyllä,\n",
            "\n",
            "\n",
            "1:  Hiano ilima! Lähretähän ulokoolemaha. Ja sitte, ku se on syöty, sen voi siirtää toiseen paikkaan. Ja se meneekin siihen paikkaan, kun se saa sen syödäkseen. Ja kun se syö sen, se syö sen. Sen ei tarvi olla mikään super-syöjä, mutta kyllä se välillä pitää sitä nälässä. Mä en ole ikinä antanut itselleni lupaa syödä herkkuja, kun ei ole ollut mahdollisuutta. Aina ne on jotain keksineitä. On pakko. Joskus on pakko ja välillä on pakko. Mutta mä en ole koskaan antanut itselleni lupaa syödä herkkuja, kun on ollut mahdollisuus. En ole myöskään antanut mitään. Oon syönyt ihan miten haluan, eikä siihen ole vaikuttanut se, että haluaisin syödä suklaata. Se on kuitenkin ollut tosi helppoa. Mä tykkään suklaasta tosi paljon. Oon syöny sitä ihan koko elämäni ja se on tosi hyvää. Ja oon saanu siitä paljon voimaa ja voimaa elämään. Se on aina ollut mun suosikki. Se on tosi paljon kevyempi kuin muut. Mä en ole ikinä ollut mikään maailman kiltein ihminen, vaan olen aina ollut hoikka. Mutta se on mun vahvuus ja se on myös mun heikkous. Ja se on myös mulle aika suuri heikkous. Se on todella heikko ja mulla on tosi heikot hampaat. Mä en pysty keskittymään mihinkään muuhun kuin siihen yhteen asiaan kerrallaan. Se ei ole mulle koskaan ollut mikään kovin hyvä asia. Mutta mä pidän sitä tärkeänä. Ja mä en koe, että mun pitäisi koskaan olla mikään super-syöjä. Mutta mä haluan niin kovasti kehittyä ja päästä taas\n",
            "\n",
            "\n",
            "2:  Hiano ilima! Lähretähän ulokoolemaha. OonaHii, onkos Hiano ollu niin suosittu että sitä on tullu joka ikiseen kauppaan? Hiano on ollu tosi suosittu kun on sen jälkee menny vähä joka paikkaan ja ei oo ollu yhtään sen isompaa ongelmaa, mut se on tosi iso ja vaikee nostaa pois sieltä, ni ei saa kunnolla edes purtua. Jos on niin iso, ni sit pitää ottaa pois. Ei tuu purettua, jos on liian iso. OonaHii!Hiano, että olet löytänyt sellaisen kaupan mistä voit ostaa hianon! Kannattaa katsoa jos on vielä myynnissä! :) OonaHii!OonaHii, se on totta. Itse ostan sieltä kun sinne menee rahaa! :) Nyt Hiao:sta ja sen vaatteista, niin siellä myydään vaatteita! :) OonaHii!Voi että, ihan mahtavaa, kun olet löytänyt oikean kauppaketjun. OonaHii! OonaHii! OonaHii, minäkin haluan sen. :P OonaHii, olet kyllä huippu, OonaHii. OonaHii, OonaHii! OonaHii, OonaHii. Ja OonaHii, OonaHii. On se mahtava kauppa, OonaHii! Ja tosiaan, OonaHii, OonaHii. OonaHii, OonaHii, OonaHii, OonaHii, OonaH\n",
            "\n",
            "\n",
            "3:  Hiano ilima! Lähretähän ulokoolemaha. Minäpä laitan tähän vielä kuvia itsestäni: Jekku. Minä! Jekku. Minä! Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä. Jekku. Minä\n",
            "\n",
            "\n",
            "4:  Hiano ilima! Lähretähän ulokoolemaha. Reenaa, ulukoolo, ilima, ilima, ulukoolo, ulukoolo! Pönttöön, ulukoolo, ilima. Ja, jotta, iliman. Oes oes vaekka! Ja jotta. Reenaa, ulukoolo, ilima, ilima, ilima, ulukoolo, ilima, ilima, ulukoolo. Pönttöön, ulukoolo, ilima, ulukoolo. Soli ilima. Pönttöön, ulukoolo, ilima, ilima, ulukoolo. Reenaa, ulukoolo, ilima, ilima, ulukoolo. Ja, jotta, ilima, ulukoolo, ilima, ulukoolo, ilima, ulukoolo. Pönttöön, ulukoolo, ilima, ulukoolo, ilima, ulukoolo, ilima, ulukoolo. Ja, jotta, ilima, ulukoolo, ilima, ulukoolo. Pönttöön, ulukoolo, ilima, ulukoolo, ilima, ulukoolo, ulukoolo. Pönttöön, ulukoolo, ilima, ulukoolo. Pönttöön, ulukoolo, ilima, ulukoolo, ulukoolo. Pönttöön, ulukoolo,\n",
            "\n",
            "\n",
            "5:  Hiano ilima! Lähretähän ulokoolemaha. Siellä on taas niin hyvää! Täälläkin on ollut tosi huono viikko. Eilen oli koko päivän ja tänäänkin on koko päivä. On tämä elämä niin kivaa, kun saa olla töissä. On niin ihanaa, kun saa olla vaan kotona. Se on niin parasta. Tänään tuli postissa, että on päässyt mökille nauttimaan. Ja huomenna saa lähteä maalle saunomaan, kun ei enää tule lämmintä vettä. Niin ihanaa. Toivottavasti tulee jo pian!.Tunnisteet: herkut, mökillä, mökillä.Nyt on ihana olla! Huomenna täytyy pakata matkalaukku ja lähteä mökille. Nyt on niin ihanaa, kun pääsee mökille. On ihanaa olla kotona ja on ihanaa saada viettää aikaa ystävien kanssa. Olen oppinut taas paljon itsestäni ja itsestäni. On ihanaa kun ei tarvitse lähteä minnekään. On ihanaa tehdä ihan mitä vaan. On ihanaa kun voi tehdä mitä vaan ja olla kotona ihan koko päivän. Kun tietää, että saa olla rauhassa, niin ei tarvitse jännittää. Mutta kun pitää olla omassa rauhassa, niin aina voi nauttia ihan kaikista ja olla kotona. On ihana olla vain kotona. Täällä on ihana käydä uimassa ja saunassa. On ihana kun on lämmin ja aurinkoinen ilma. On ihanaa mennä ulos ja saunoa kun on sisällä. On ihanaa kun saa rentoutua rauhassa ja kun voi tehdä mitä vaan, niin saa tehdä mitä vaan. On ihana käydä mökillä ja tehdä kaikkea ihanaa. On ihanaa kun voi tehdä mitä vain, niin saa tehdä mitä vaan ja olla ihan rauhassa. On ihana, kun voi tehdä mitä vain ja saada aikaan jotakin\n",
            "\n",
            "\n",
            "6:  Hiano ilima! Lähretähän ulokoolemaha. Tuskimpa sulle. On se mukava! Tuskimpa sulle. Tuskimpa sulle. On se mukava! Tuskimpa sulle. On se mukava! Tuskimpa sulle. On se mukava! Tuskimpa sulle. On se mukava! Tuskimpa sulle. On se mukava! Tuskimpa sulle. On se mukava! Tuskimpa sulle. On se mukava! Tuskimpa sulle. On se mukava! Tuskimpa sulle. On se mukava! Tuskimpa sulle. On se mukava! Tuskimpa sulle. On se mukava! Tuskimpa sulle. On se mukava! Tuskimpa sulle. On se mukava! Tuskimpa sulle. On se mukava! Tuskimpa sulle. On se mukava! Tuskimpa sulle. On se mukava! Tuskimpa sinulle. On se mukava! Tuskimpa sinulle. On se mukava! Tuskimpa sinulle. On se mukava! Tuskimpa sinulle. On se mukava! Tuskimpa sinulle. On se mukava! Tuskimpa sinulle. On se mukava! Tuskimpa sinulle. On se mukava! Tuskimpa sinulle. On se mukava! Tuskimpa sinulle. On se mukava! Tuskimpa sinulle. On se mukava! Tuskimpa sinulle. On se mukava\n",
            "\n",
            "\n",
            "7:  Hiano ilima! Lähretähän ulokoolemaha. Nyt kyllä pitää päästä jo kotiin. Olen ollut nyt viikon poissa töistä, ja kylläpäs on ollut raskasta. Eilen en voinut kun olla rauhassa kotona ja lähteä, mutta tänään sitten. Olen kyllä kuullut, että täällä on ollut tosi huono ilmasto, en ole ollut kovin mukava ihminen kun olen ollut koko päivän töissä. Nyt kun olen kotona niin pitää lähteä ulos nauttimaan ja nauttimaan. Niin ja sitten vielä tänään, että saan mennä yksin uimaan, mutta se sitten onkin jo ihan toinen juttu, sillä tänään on kuitenkin tosi lämmin päivä ja aion mennä taas sinne. Huomenna sitten taas. Jos teillä muilla menee hyvin, niin mikä tahansa aika ja paikka siellä voisi olla parempi? Ja se, että miksi ihmiset menevät nyt töihin niin huonosti? Mikä heitä oikein vaivaa? Mitä tehdä kun on niin paljon töitä ja on niin tylsää? Ei ole kiva mennä aamulla töihin ja mennä illalla kotiin. On niin väsyttävää, että tekisi mieli lähteä vaikka heti. Ei ole kivaa, kun on niin väsynyt ja kaikki ahdistaa. Miksi sitten menin töihin ja menin nukkumaan? En ollut kauhean hyvä nukkuja ja menin sitten aikaisin nukkumaan ja nukkumaan. Menin sitten illalla kotiin ja menin taas nukkumaan ja menin sitten taas nukkumaan. Ihan kivaa oli, mutta huomenna pitäisi sitten lähteä taas mökille. Ja sitten huomenna pitää lähteä taas töihin ja mennä kotiin. Onko joku muu samaa mieltä? Olen aina vähän huolissani tästä meidän perheestäni, kun on niin huono elämä täällä. Ihan kauheaa kun ei voi enää elää niin pitkään! Nyt sitten yritän\n",
            "\n",
            "\n",
            "8:  Hiano ilima! Lähretähän ulokoolemaha. Syön hyvin, ja vatsakin on kunnossa. Hiao on kyllä jo nyt niin täynnä ettei ole mitään hätää. Hiao ei ole ikinä ollut paha, mutta sen verran ärsyttävä, että pitää syödä paljon ja vähän. Ja en syö mitään herkkuja. Joten miksi tämä on niin vaikeaa? Minä syön ja se on hyvää. Onko jotain pakko syödä tai jos syö enemmän niin ei syö. Eli kertokaa, mistä saa ruokaa ja mitä voi syödä? Mitä voi laittaa ja mitä ei. Kiitos!on kyllä totta että vatsalaukku on todella löysällä! itse olen kärsinyt mahakivuista jo pari kuukautta. itselläni on ihan sama tilanne kun sulla, mutta olen myös kuullut että vatsalaukku on jumissa ja on myös erittäin ärsyttävää syödä mitään herkkuja, vaikka kyllä se siitä menee ohi. mutta olen myös kuullut että vatsalaukun toiminta häiriintyy jos syön vain yhden kerran päivässä, enkä syö mitään herkkuja tai herkkuja. siis mitä pitää syödä? eli siis ihan oikeesti mistä saa sitä ruokaa? en muista koska olisin viimeksi ollut niin kipeä. ja onko teillä ollut sellaista ongelmaa että esim. kun syö jotain ja ruoka on huonoa ja syö sitten jotain niin vatsa ei reagoi mitenkään? eli jos kerran syö paljon niin ei reagoi mitenkään? jos ei ole nälkä niin sitten ei reagoi mitenkään. ja myös jos ei syö tarpeeksi niin se ei reagoi mitenkään. eli vaikka söis monta kertaa päivässä niin vatsa ei reagoi mitenkään, sitten taas kun syö tarpeeksi ei reagoi ollenkaan. mutta jos syö jotain muuta ja\n",
            "\n",
            "\n",
            "9:  Hiano ilima! Lähretähän ulokoolemaha. Sooda ei pala pohjaan! Ja mitä se maksaa? Ei kai kukaan osta sellaista? Jos ei, niin mitä se maksaa? Ja sitten, mistä löytyy se oikea varaosa? Ja mistä sen löytäisi ja milloin ja missä paikassa? Kiitti jo etukäteen vastanneille!se on ihan sitä samaa kun mä oon sitä mieltä että kyllä ne on aina valmiita maksamaan siitä hyvästä että on varaosia. Ja että varaosat on laadukkaita. Ei ne voi olla jotain ylihinnoiteltuja, jos ne vaan pitää hankkia. Mutta kyllä niitä on ja varaosat voi aina hankkia sieltä, jos on tarve. Mutta sitten ne on sellaisia, että ne pitää ostaa jostain muualta, eikä siitä, että on kallista maksaa jostakin muusta. Mutta ei se haittaa, koska mä ainakin sain ainakin sen verran, ettei tarvinnut mistään muualta ostaa kuin sieltä mistä oli tarve. Ja en mä sitä vaan sitä, että kun ne on ihan halpoja. Ne on kalliimpia kuin mitä niitä on tarjolla. Ja koska ne on kalliimpia, on ne kalliimpia. Joo mä oon kyllä samaa mieltä että kyllä se on aina parempi että se varaosa tulee sieltä. Mutta ei se haittaa, koska ne on vaan halpoja, eikä niiden tarvitse olla kalliita. Mutta on olemassa joku halpa huoltofirma, joka on hinnoitellut ne siihen kuntoon että ne on siellä, että niillä on helppo ja halpa ostaa, kun ne on halvempia kuin esim. merkkiliikeissä. Ja koska nämä on halpoja, ja niin kuin sanoin, ei ne välttämättä ole halpoja, ja jos\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}